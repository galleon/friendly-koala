## Examples of real-world applications
### HuggingFace transformers
### Other models usages (TBC)

# Part 2 from recurrent networks to transformers

## Recurrent Neural networks [GD]
### Principles
### LSTM & GRU cells
### Architectures
### RNN Unfolding & bidirectional RNN
### Constraints and limitations
### Summary

## Attention networks [GD]
### Principles
### Training
### Summary

## Transformer 
### Encoder/decoder architecture
### Self-supervised training
### Multi-head attention
### Fine-tuning approach
### Multi-task learning
### Synthesis

# Part 3 Transformers in Action

## Using transformers for NLP [GD]
### Basic concepts 
### Key models and libraries - HuggingFace transformers 
### Training for end-tasks
### Summary

## Using transformers for computer vision [GAL]
### Basic concepts 
### Key models and libraries
### Training for end-tasks
### Summary

## Using transformers for time series [GAL]
### Basic concepts 
### Key models and libraries
### Training for end-tasks
### Summary

## Using transformers for decision making [GD]?
### Basic concepts 
### Key models and libraries
### Training for end-tasks
### Summary

## Beyond Vanilla Transformer [GD]
### Transformer evolution: future research paths
Interpretation of models
Bigger models
Smaller models
### Major research papers

